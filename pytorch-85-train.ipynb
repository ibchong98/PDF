{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-10T12:06:29.371528Z",
     "iopub.status.busy": "2021-02-10T12:06:29.368188Z",
     "iopub.status.idle": "2021-02-10T16:27:54.077345Z",
     "shell.execute_reply": "2021-02-10T16:27:54.077931Z"
    },
    "papermill": {
     "duration": 15684.731868,
     "end_time": "2021-02-10T16:27:54.078302",
     "exception": false,
     "start_time": "2021-02-10T12:06:29.346434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold0:\n",
      "FOLD0 EPOCH:  0 train_loss=0.69229 valid_u_score=1705.18159 valid_auc=0.54655 time: 1.00min\n",
      "FOLD0 EPOCH:  1 train_loss=0.68979 valid_u_score=1775.34960 valid_auc=0.54931 time: 1.91min\n",
      "FOLD0 EPOCH:  2 train_loss=0.68913 valid_u_score=1981.09315 valid_auc=0.55046 time: 2.81min\n",
      "FOLD0 EPOCH:  3 train_loss=0.68872 valid_u_score=1987.40307 valid_auc=0.54843 time: 3.71min\n",
      "FOLD0 EPOCH:  4 train_loss=0.68839 valid_u_score=1978.15193 valid_auc=0.55057 time: 4.63min\n",
      "FOLD0 EPOCH:  5 train_loss=0.68808 valid_u_score=1872.87273 valid_auc=0.55126 time: 5.53min\n",
      "FOLD0 EPOCH:  6 train_loss=0.68782 valid_u_score=1877.99167 valid_auc=0.54984 time: 6.44min\n",
      "FOLD0 EPOCH:  7 train_loss=0.68751 valid_u_score=2011.69693 valid_auc=0.55051 time: 7.35min\n",
      "FOLD0 EPOCH:  8 train_loss=0.68725 valid_u_score=2204.02717 valid_auc=0.55119 time: 8.26min\n",
      "FOLD0 EPOCH:  9 train_loss=0.68705 valid_u_score=1889.06199 valid_auc=0.55048 time: 9.17min\n",
      "FOLD0 EPOCH: 10 train_loss=0.68668 valid_u_score=1835.42764 valid_auc=0.55390 time: 10.07min\n",
      "FOLD0 EPOCH: 11 train_loss=0.68648 valid_u_score=1985.99336 valid_auc=0.55084 time: 10.97min\n",
      "FOLD0 EPOCH: 12 train_loss=0.68615 valid_u_score=1764.32385 valid_auc=0.54927 time: 11.88min\n",
      "FOLD0 EPOCH: 13 train_loss=0.68583 valid_u_score=1830.45535 valid_auc=0.55033 time: 12.78min\n",
      "FOLD0 EPOCH: 14 train_loss=0.68554 valid_u_score=1743.08057 valid_auc=0.55172 time: 13.68min\n",
      "FOLD0 EPOCH: 15 train_loss=0.68525 valid_u_score=1658.62776 valid_auc=0.55075 time: 14.59min\n",
      "FOLD0 EPOCH: 16 train_loss=0.68484 valid_u_score=1659.54232 valid_auc=0.54823 time: 15.50min\n",
      "FOLD0 EPOCH: 17 train_loss=0.68453 valid_u_score=1672.21219 valid_auc=0.55234 time: 16.38min\n",
      "FOLD0 EPOCH: 18 train_loss=0.68425 valid_u_score=1799.73034 valid_auc=0.55013 time: 17.29min\n",
      "FOLD0 EPOCH: 19 train_loss=0.68384 valid_u_score=1629.59023 valid_auc=0.55095 time: 18.17min\n",
      "FOLD0 EPOCH: 20 train_loss=0.68359 valid_u_score=1809.20287 valid_auc=0.54949 time: 19.07min\n",
      "FOLD0 EPOCH: 21 train_loss=0.68324 valid_u_score=1079.15003 valid_auc=0.54829 time: 19.96min\n",
      "FOLD0 EPOCH: 22 train_loss=0.68292 valid_u_score=1610.39225 valid_auc=0.54946 time: 20.84min\n",
      "FOLD0 EPOCH: 23 train_loss=0.68263 valid_u_score=1763.01609 valid_auc=0.54994 time: 21.74min\n",
      "FOLD0 EPOCH: 24 train_loss=0.68223 valid_u_score=1583.75091 valid_auc=0.54943 time: 22.63min\n",
      "FOLD0 EPOCH: 25 train_loss=0.68198 valid_u_score=1684.96195 valid_auc=0.54767 time: 23.52min\n",
      "FOLD0 EPOCH: 26 train_loss=0.68164 valid_u_score=1468.32248 valid_auc=0.54694 time: 24.41min\n",
      "FOLD0 EPOCH: 27 train_loss=0.68146 valid_u_score=1820.21031 valid_auc=0.54706 time: 25.29min\n",
      "FOLD0 EPOCH: 28 train_loss=0.68110 valid_u_score=1635.18275 valid_auc=0.54772 time: 26.19min\n",
      "FOLD0 EPOCH: 29 train_loss=0.68084 valid_u_score=1637.99830 valid_auc=0.54829 time: 27.08min\n",
      "FOLD0 EPOCH: 30 train_loss=0.68061 valid_u_score=1460.53487 valid_auc=0.54600 time: 27.96min\n",
      "Early stopping\n",
      "Fold1:\n",
      "FOLD1 EPOCH:  0 train_loss=0.69264 valid_u_score=1914.27808 valid_auc=0.54819 time: 28.85min\n",
      "FOLD1 EPOCH:  1 train_loss=0.68973 valid_u_score=1911.46245 valid_auc=0.54947 time: 29.73min\n",
      "FOLD1 EPOCH:  2 train_loss=0.68915 valid_u_score=1671.56933 valid_auc=0.54801 time: 30.61min\n",
      "FOLD1 EPOCH:  3 train_loss=0.68880 valid_u_score=2195.71693 valid_auc=0.55246 time: 31.50min\n",
      "FOLD1 EPOCH:  4 train_loss=0.68843 valid_u_score=2382.53796 valid_auc=0.55144 time: 32.39min\n",
      "FOLD1 EPOCH:  5 train_loss=0.68806 valid_u_score=2063.93941 valid_auc=0.55045 time: 33.29min\n",
      "FOLD1 EPOCH:  6 train_loss=0.68788 valid_u_score=1867.98310 valid_auc=0.55093 time: 34.20min\n",
      "FOLD1 EPOCH:  7 train_loss=0.68763 valid_u_score=1971.59983 valid_auc=0.55214 time: 35.11min\n",
      "FOLD1 EPOCH:  8 train_loss=0.68723 valid_u_score=2095.51472 valid_auc=0.55188 time: 36.04min\n",
      "FOLD1 EPOCH:  9 train_loss=0.68696 valid_u_score=2000.33714 valid_auc=0.55154 time: 36.95min\n",
      "FOLD1 EPOCH: 10 train_loss=0.68670 valid_u_score=1940.02325 valid_auc=0.55024 time: 37.86min\n",
      "FOLD1 EPOCH: 11 train_loss=0.68643 valid_u_score=1791.34139 valid_auc=0.54970 time: 38.77min\n",
      "FOLD1 EPOCH: 12 train_loss=0.68611 valid_u_score=1722.53311 valid_auc=0.55093 time: 39.67min\n",
      "FOLD1 EPOCH: 13 train_loss=0.68578 valid_u_score=1868.38823 valid_auc=0.54974 time: 40.59min\n",
      "FOLD1 EPOCH: 14 train_loss=0.68544 valid_u_score=1524.56042 valid_auc=0.54940 time: 41.51min\n",
      "FOLD1 EPOCH: 15 train_loss=0.68516 valid_u_score=1751.23381 valid_auc=0.54993 time: 42.43min\n",
      "FOLD1 EPOCH: 16 train_loss=0.68487 valid_u_score=1637.52225 valid_auc=0.54926 time: 43.35min\n",
      "FOLD1 EPOCH: 17 train_loss=0.68452 valid_u_score=1436.39395 valid_auc=0.55028 time: 44.27min\n",
      "FOLD1 EPOCH: 18 train_loss=0.68413 valid_u_score=1528.52053 valid_auc=0.55061 time: 45.18min\n",
      "FOLD1 EPOCH: 19 train_loss=0.68387 valid_u_score=1638.57584 valid_auc=0.54916 time: 46.09min\n",
      "FOLD1 EPOCH: 20 train_loss=0.68358 valid_u_score=1200.45938 valid_auc=0.54938 time: 47.00min\n",
      "FOLD1 EPOCH: 21 train_loss=0.68324 valid_u_score=1465.42287 valid_auc=0.54941 time: 47.91min\n",
      "FOLD1 EPOCH: 22 train_loss=0.68295 valid_u_score=1602.23879 valid_auc=0.55006 time: 48.82min\n",
      "FOLD1 EPOCH: 23 train_loss=0.68263 valid_u_score=899.25011 valid_auc=0.54873 time: 49.73min\n",
      "Early stopping\n",
      "Fold2:\n",
      "FOLD2 EPOCH:  0 train_loss=0.69223 valid_u_score=1970.49936 valid_auc=0.54852 time: 50.62min\n",
      "FOLD2 EPOCH:  1 train_loss=0.68970 valid_u_score=2103.07937 valid_auc=0.54971 time: 51.53min\n",
      "FOLD2 EPOCH:  2 train_loss=0.68918 valid_u_score=2394.89241 valid_auc=0.55060 time: 52.45min\n",
      "FOLD2 EPOCH:  3 train_loss=0.68879 valid_u_score=2200.45590 valid_auc=0.55189 time: 53.36min\n",
      "FOLD2 EPOCH:  4 train_loss=0.68841 valid_u_score=2229.41881 valid_auc=0.55071 time: 54.28min\n",
      "FOLD2 EPOCH:  5 train_loss=0.68808 valid_u_score=2101.30786 valid_auc=0.55161 time: 55.19min\n",
      "FOLD2 EPOCH:  6 train_loss=0.68782 valid_u_score=1894.94072 valid_auc=0.55114 time: 56.10min\n",
      "FOLD2 EPOCH:  7 train_loss=0.68752 valid_u_score=1720.90186 valid_auc=0.55097 time: 57.02min\n",
      "FOLD2 EPOCH:  8 train_loss=0.68723 valid_u_score=1917.61552 valid_auc=0.55171 time: 57.94min\n",
      "FOLD2 EPOCH:  9 train_loss=0.68690 valid_u_score=1386.94120 valid_auc=0.55126 time: 58.84min\n",
      "FOLD2 EPOCH: 10 train_loss=0.68661 valid_u_score=2076.40440 valid_auc=0.55133 time: 59.75min\n",
      "FOLD2 EPOCH: 11 train_loss=0.68634 valid_u_score=1771.04837 valid_auc=0.55081 time: 60.66min\n",
      "FOLD2 EPOCH: 12 train_loss=0.68610 valid_u_score=1722.90191 valid_auc=0.55047 time: 61.57min\n",
      "FOLD2 EPOCH: 13 train_loss=0.68580 valid_u_score=1583.61592 valid_auc=0.54982 time: 62.49min\n",
      "FOLD2 EPOCH: 14 train_loss=0.68548 valid_u_score=1730.49269 valid_auc=0.55034 time: 63.41min\n",
      "FOLD2 EPOCH: 15 train_loss=0.68516 valid_u_score=1698.71069 valid_auc=0.55033 time: 64.32min\n",
      "FOLD2 EPOCH: 16 train_loss=0.68486 valid_u_score=1589.83765 valid_auc=0.54914 time: 65.23min\n",
      "FOLD2 EPOCH: 17 train_loss=0.68445 valid_u_score=1779.35910 valid_auc=0.54984 time: 66.13min\n",
      "FOLD2 EPOCH: 18 train_loss=0.68416 valid_u_score=1197.33644 valid_auc=0.54953 time: 67.03min\n",
      "FOLD2 EPOCH: 19 train_loss=0.68387 valid_u_score=1531.90632 valid_auc=0.54911 time: 67.93min\n",
      "FOLD2 EPOCH: 20 train_loss=0.68347 valid_u_score=1571.58505 valid_auc=0.55013 time: 68.84min\n",
      "FOLD2 EPOCH: 21 train_loss=0.68323 valid_u_score=1190.90013 valid_auc=0.54836 time: 69.73min\n",
      "FOLD2 EPOCH: 22 train_loss=0.68287 valid_u_score=1566.21778 valid_auc=0.55148 time: 70.64min\n",
      "FOLD2 EPOCH: 23 train_loss=0.68258 valid_u_score=1520.50438 valid_auc=0.54840 time: 71.55min\n",
      "Early stopping\n",
      "Fold3:\n",
      "FOLD3 EPOCH:  0 train_loss=0.69253 valid_u_score=2209.80698 valid_auc=0.54581 time: 72.45min\n",
      "FOLD3 EPOCH:  1 train_loss=0.68979 valid_u_score=1865.45308 valid_auc=0.54858 time: 73.37min\n",
      "FOLD3 EPOCH:  2 train_loss=0.68913 valid_u_score=1904.09006 valid_auc=0.54990 time: 74.27min\n",
      "FOLD3 EPOCH:  3 train_loss=0.68878 valid_u_score=2085.33115 valid_auc=0.54994 time: 75.18min\n",
      "FOLD3 EPOCH:  4 train_loss=0.68842 valid_u_score=2067.05807 valid_auc=0.55275 time: 76.08min\n",
      "FOLD3 EPOCH:  5 train_loss=0.68809 valid_u_score=1983.13798 valid_auc=0.54950 time: 77.00min\n",
      "FOLD3 EPOCH:  6 train_loss=0.68783 valid_u_score=2104.66113 valid_auc=0.55254 time: 77.91min\n",
      "FOLD3 EPOCH:  7 train_loss=0.68756 valid_u_score=2307.02448 valid_auc=0.55101 time: 78.81min\n",
      "FOLD3 EPOCH:  8 train_loss=0.68724 valid_u_score=1735.86917 valid_auc=0.54995 time: 79.73min\n",
      "FOLD3 EPOCH:  9 train_loss=0.68697 valid_u_score=1896.20101 valid_auc=0.55030 time: 80.64min\n",
      "FOLD3 EPOCH: 10 train_loss=0.68675 valid_u_score=1843.16003 valid_auc=0.55100 time: 81.54min\n",
      "FOLD3 EPOCH: 11 train_loss=0.68642 valid_u_score=1530.18242 valid_auc=0.55106 time: 82.46min\n",
      "FOLD3 EPOCH: 12 train_loss=0.68616 valid_u_score=1716.82787 valid_auc=0.55149 time: 83.37min\n",
      "FOLD3 EPOCH: 13 train_loss=0.68585 valid_u_score=1673.88922 valid_auc=0.55212 time: 84.27min\n",
      "FOLD3 EPOCH: 14 train_loss=0.68554 valid_u_score=1691.02374 valid_auc=0.54980 time: 85.18min\n",
      "FOLD3 EPOCH: 15 train_loss=0.68525 valid_u_score=1887.87174 valid_auc=0.55164 time: 86.09min\n",
      "FOLD3 EPOCH: 16 train_loss=0.68489 valid_u_score=1396.45740 valid_auc=0.54993 time: 87.00min\n",
      "FOLD3 EPOCH: 17 train_loss=0.68463 valid_u_score=1719.33173 valid_auc=0.55087 time: 87.91min\n",
      "FOLD3 EPOCH: 18 train_loss=0.68433 valid_u_score=1715.71741 valid_auc=0.54925 time: 88.83min\n",
      "FOLD3 EPOCH: 19 train_loss=0.68400 valid_u_score=1703.02812 valid_auc=0.55109 time: 89.75min\n",
      "FOLD3 EPOCH: 20 train_loss=0.68352 valid_u_score=1644.53635 valid_auc=0.55126 time: 90.65min\n",
      "FOLD3 EPOCH: 21 train_loss=0.68330 valid_u_score=1266.50196 valid_auc=0.54739 time: 91.57min\n",
      "FOLD3 EPOCH: 22 train_loss=0.68296 valid_u_score=1959.16894 valid_auc=0.55075 time: 92.48min\n",
      "FOLD3 EPOCH: 23 train_loss=0.68269 valid_u_score=1408.25755 valid_auc=0.54945 time: 93.38min\n",
      "FOLD3 EPOCH: 24 train_loss=0.68241 valid_u_score=1665.56892 valid_auc=0.54838 time: 94.29min\n",
      "Early stopping\n",
      "Fold4:\n",
      "FOLD4 EPOCH:  0 train_loss=0.69224 valid_u_score=1931.65508 valid_auc=0.54873 time: 95.20min\n",
      "FOLD4 EPOCH:  1 train_loss=0.68971 valid_u_score=2067.32400 valid_auc=0.55065 time: 96.10min\n",
      "FOLD4 EPOCH:  2 train_loss=0.68913 valid_u_score=1932.62970 valid_auc=0.55034 time: 97.02min\n",
      "FOLD4 EPOCH:  3 train_loss=0.68875 valid_u_score=2199.77980 valid_auc=0.55116 time: 97.93min\n",
      "FOLD4 EPOCH:  4 train_loss=0.68837 valid_u_score=1827.35485 valid_auc=0.54987 time: 98.84min\n",
      "FOLD4 EPOCH:  5 train_loss=0.68807 valid_u_score=1950.97677 valid_auc=0.55005 time: 99.75min\n",
      "FOLD4 EPOCH:  6 train_loss=0.68776 valid_u_score=2091.65092 valid_auc=0.55112 time: 100.66min\n",
      "FOLD4 EPOCH:  7 train_loss=0.68748 valid_u_score=2039.40323 valid_auc=0.55056 time: 101.58min\n",
      "FOLD4 EPOCH:  8 train_loss=0.68717 valid_u_score=1871.82362 valid_auc=0.55091 time: 102.48min\n",
      "FOLD4 EPOCH:  9 train_loss=0.68693 valid_u_score=1657.58241 valid_auc=0.55091 time: 103.39min\n",
      "FOLD4 EPOCH: 10 train_loss=0.68664 valid_u_score=1627.87389 valid_auc=0.55052 time: 104.31min\n",
      "FOLD4 EPOCH: 11 train_loss=0.68623 valid_u_score=1758.25539 valid_auc=0.55166 time: 105.21min\n",
      "FOLD4 EPOCH: 12 train_loss=0.68603 valid_u_score=1663.13432 valid_auc=0.54918 time: 106.13min\n",
      "FOLD4 EPOCH: 13 train_loss=0.68573 valid_u_score=1420.55725 valid_auc=0.54906 time: 107.05min\n",
      "FOLD4 EPOCH: 14 train_loss=0.68533 valid_u_score=1482.91704 valid_auc=0.55060 time: 107.95min\n",
      "FOLD4 EPOCH: 15 train_loss=0.68506 valid_u_score=1643.59309 valid_auc=0.54957 time: 108.86min\n",
      "FOLD4 EPOCH: 16 train_loss=0.68480 valid_u_score=1546.28120 valid_auc=0.54963 time: 109.77min\n",
      "FOLD4 EPOCH: 17 train_loss=0.68437 valid_u_score=1798.64580 valid_auc=0.55133 time: 110.67min\n",
      "FOLD4 EPOCH: 18 train_loss=0.68401 valid_u_score=1140.64565 valid_auc=0.54845 time: 111.57min\n",
      "FOLD4 EPOCH: 19 train_loss=0.68382 valid_u_score=1781.10179 valid_auc=0.55056 time: 112.48min\n",
      "FOLD4 EPOCH: 20 train_loss=0.68351 valid_u_score=884.08750 valid_auc=0.54845 time: 113.39min\n",
      "FOLD4 EPOCH: 21 train_loss=0.68314 valid_u_score=1330.85397 valid_auc=0.55020 time: 114.29min\n",
      "FOLD4 EPOCH: 22 train_loss=0.68285 valid_u_score=1486.29682 valid_auc=0.54861 time: 115.20min\n",
      "FOLD4 EPOCH: 23 train_loss=0.68260 valid_u_score=1731.05593 valid_auc=0.54881 time: 116.12min\n",
      "FOLD4 EPOCH: 24 train_loss=0.68236 valid_u_score=1478.54567 valid_auc=0.54932 time: 117.01min\n",
      "FOLD4 EPOCH: 25 train_loss=0.68203 valid_u_score=1365.45493 valid_auc=0.54797 time: 117.93min\n",
      "FOLD4 EPOCH: 26 train_loss=0.68175 valid_u_score=1666.72866 valid_auc=0.54934 time: 118.84min\n",
      "FOLD4 EPOCH: 27 train_loss=0.68150 valid_u_score=1696.53684 valid_auc=0.55021 time: 119.74min\n",
      "FOLD4 EPOCH: 28 train_loss=0.68115 valid_u_score=1538.12349 valid_auc=0.54822 time: 120.65min\n",
      "FOLD4 EPOCH: 29 train_loss=0.68106 valid_u_score=1061.42853 valid_auc=0.54966 time: 121.56min\n",
      "FOLD4 EPOCH: 30 train_loss=0.68073 valid_u_score=1663.41245 valid_auc=0.55051 time: 122.46min\n",
      "FOLD4 EPOCH: 31 train_loss=0.68039 valid_u_score=1657.48668 valid_auc=0.54873 time: 123.37min\n",
      "Early stopping\n",
      "Fold5:\n",
      "FOLD5 EPOCH:  0 train_loss=0.69260 valid_u_score=1965.01786 valid_auc=0.54724 time: 124.29min\n",
      "FOLD5 EPOCH:  1 train_loss=0.68974 valid_u_score=1814.87993 valid_auc=0.54755 time: 125.18min\n",
      "FOLD5 EPOCH:  2 train_loss=0.68915 valid_u_score=2287.29471 valid_auc=0.55043 time: 126.10min\n",
      "FOLD5 EPOCH:  3 train_loss=0.68874 valid_u_score=2153.05425 valid_auc=0.55171 time: 127.01min\n",
      "FOLD5 EPOCH:  4 train_loss=0.68837 valid_u_score=1930.25498 valid_auc=0.54982 time: 127.92min\n",
      "FOLD5 EPOCH:  5 train_loss=0.68809 valid_u_score=2088.76457 valid_auc=0.55136 time: 128.83min\n",
      "FOLD5 EPOCH:  6 train_loss=0.68776 valid_u_score=2211.74032 valid_auc=0.55238 time: 129.74min\n",
      "FOLD5 EPOCH:  7 train_loss=0.68748 valid_u_score=2168.28985 valid_auc=0.55097 time: 130.66min\n",
      "FOLD5 EPOCH:  8 train_loss=0.68723 valid_u_score=1949.52395 valid_auc=0.55085 time: 131.56min\n",
      "FOLD5 EPOCH:  9 train_loss=0.68695 valid_u_score=1696.78102 valid_auc=0.55045 time: 132.47min\n",
      "FOLD5 EPOCH: 10 train_loss=0.68662 valid_u_score=1586.08976 valid_auc=0.55107 time: 133.37min\n",
      "FOLD5 EPOCH: 11 train_loss=0.68638 valid_u_score=1766.28720 valid_auc=0.55024 time: 134.28min\n",
      "FOLD5 EPOCH: 12 train_loss=0.68611 valid_u_score=1756.66059 valid_auc=0.55197 time: 135.19min\n",
      "FOLD5 EPOCH: 13 train_loss=0.68577 valid_u_score=1614.38628 valid_auc=0.54923 time: 136.10min\n",
      "FOLD5 EPOCH: 14 train_loss=0.68548 valid_u_score=1649.11057 valid_auc=0.54961 time: 137.01min\n",
      "FOLD5 EPOCH: 15 train_loss=0.68524 valid_u_score=1627.90186 valid_auc=0.55009 time: 137.92min\n",
      "FOLD5 EPOCH: 16 train_loss=0.68490 valid_u_score=1782.49070 valid_auc=0.55036 time: 138.82min\n",
      "FOLD5 EPOCH: 17 train_loss=0.68455 valid_u_score=1442.84374 valid_auc=0.54879 time: 139.73min\n",
      "FOLD5 EPOCH: 18 train_loss=0.68428 valid_u_score=1727.54491 valid_auc=0.54884 time: 140.63min\n",
      "FOLD5 EPOCH: 19 train_loss=0.68396 valid_u_score=1674.34050 valid_auc=0.54913 time: 141.54min\n",
      "FOLD5 EPOCH: 20 train_loss=0.68360 valid_u_score=1605.36868 valid_auc=0.54948 time: 142.45min\n",
      "FOLD5 EPOCH: 21 train_loss=0.68330 valid_u_score=1847.93310 valid_auc=0.55041 time: 143.35min\n",
      "FOLD5 EPOCH: 22 train_loss=0.68296 valid_u_score=1508.72708 valid_auc=0.54868 time: 144.25min\n",
      "FOLD5 EPOCH: 23 train_loss=0.68278 valid_u_score=1645.41561 valid_auc=0.54892 time: 145.15min\n",
      "FOLD5 EPOCH: 24 train_loss=0.68230 valid_u_score=1679.05876 valid_auc=0.54862 time: 146.06min\n",
      "FOLD5 EPOCH: 25 train_loss=0.68205 valid_u_score=1495.48207 valid_auc=0.54904 time: 146.97min\n",
      "FOLD5 EPOCH: 26 train_loss=0.68175 valid_u_score=1626.36863 valid_auc=0.54932 time: 147.86min\n",
      "Early stopping\n",
      "Fold6:\n",
      "FOLD6 EPOCH:  0 train_loss=0.69238 valid_u_score=1879.75952 valid_auc=0.54679 time: 148.77min\n",
      "FOLD6 EPOCH:  1 train_loss=0.68973 valid_u_score=1768.20940 valid_auc=0.54901 time: 149.67min\n",
      "FOLD6 EPOCH:  2 train_loss=0.68922 valid_u_score=1981.80828 valid_auc=0.55086 time: 150.58min\n",
      "FOLD6 EPOCH:  3 train_loss=0.68871 valid_u_score=1870.04409 valid_auc=0.54899 time: 151.48min\n",
      "FOLD6 EPOCH:  4 train_loss=0.68836 valid_u_score=2176.15708 valid_auc=0.55206 time: 152.38min\n",
      "FOLD6 EPOCH:  5 train_loss=0.68808 valid_u_score=2314.60662 valid_auc=0.55305 time: 153.29min\n",
      "FOLD6 EPOCH:  6 train_loss=0.68775 valid_u_score=1973.83240 valid_auc=0.54942 time: 154.20min\n",
      "FOLD6 EPOCH:  7 train_loss=0.68742 valid_u_score=2047.56817 valid_auc=0.55255 time: 155.12min\n",
      "FOLD6 EPOCH:  8 train_loss=0.68724 valid_u_score=1731.41305 valid_auc=0.54879 time: 156.04min\n",
      "FOLD6 EPOCH:  9 train_loss=0.68688 valid_u_score=1912.88059 valid_auc=0.55154 time: 156.94min\n",
      "FOLD6 EPOCH: 10 train_loss=0.68662 valid_u_score=1754.31014 valid_auc=0.54917 time: 157.86min\n",
      "FOLD6 EPOCH: 11 train_loss=0.68626 valid_u_score=1832.62342 valid_auc=0.55129 time: 158.78min\n",
      "FOLD6 EPOCH: 12 train_loss=0.68607 valid_u_score=1755.37002 valid_auc=0.55154 time: 159.68min\n",
      "FOLD6 EPOCH: 13 train_loss=0.68567 valid_u_score=1799.79237 valid_auc=0.55000 time: 160.61min\n",
      "FOLD6 EPOCH: 14 train_loss=0.68534 valid_u_score=1829.35717 valid_auc=0.54997 time: 161.52min\n",
      "FOLD6 EPOCH: 15 train_loss=0.68501 valid_u_score=1923.71203 valid_auc=0.55003 time: 162.43min\n",
      "FOLD6 EPOCH: 16 train_loss=0.68478 valid_u_score=1868.05106 valid_auc=0.55073 time: 163.34min\n",
      "FOLD6 EPOCH: 17 train_loss=0.68434 valid_u_score=1733.04656 valid_auc=0.55049 time: 164.26min\n",
      "FOLD6 EPOCH: 18 train_loss=0.68410 valid_u_score=1437.20058 valid_auc=0.54910 time: 165.17min\n",
      "FOLD6 EPOCH: 19 train_loss=0.68380 valid_u_score=1817.00512 valid_auc=0.54966 time: 166.08min\n",
      "FOLD6 EPOCH: 20 train_loss=0.68349 valid_u_score=1579.33161 valid_auc=0.55143 time: 167.00min\n",
      "FOLD6 EPOCH: 21 train_loss=0.68317 valid_u_score=1884.34333 valid_auc=0.55146 time: 167.91min\n",
      "FOLD6 EPOCH: 22 train_loss=0.68287 valid_u_score=1867.14890 valid_auc=0.54962 time: 168.82min\n",
      "FOLD6 EPOCH: 23 train_loss=0.68251 valid_u_score=1672.09594 valid_auc=0.54946 time: 169.74min\n",
      "FOLD6 EPOCH: 24 train_loss=0.68216 valid_u_score=1657.70252 valid_auc=0.55120 time: 170.65min\n",
      "FOLD6 EPOCH: 25 train_loss=0.68189 valid_u_score=1956.61041 valid_auc=0.55066 time: 171.57min\n",
      "Early stopping\n",
      "Fold7:\n",
      "FOLD7 EPOCH:  0 train_loss=0.69258 valid_u_score=1661.24418 valid_auc=0.54743 time: 172.49min\n",
      "FOLD7 EPOCH:  1 train_loss=0.68973 valid_u_score=1852.51920 valid_auc=0.55026 time: 173.40min\n",
      "FOLD7 EPOCH:  2 train_loss=0.68912 valid_u_score=2020.20325 valid_auc=0.54926 time: 174.31min\n",
      "FOLD7 EPOCH:  3 train_loss=0.68871 valid_u_score=1912.19782 valid_auc=0.54945 time: 175.23min\n",
      "FOLD7 EPOCH:  4 train_loss=0.68836 valid_u_score=1924.91601 valid_auc=0.55007 time: 176.13min\n",
      "FOLD7 EPOCH:  5 train_loss=0.68806 valid_u_score=2204.75312 valid_auc=0.55087 time: 177.04min\n",
      "FOLD7 EPOCH:  6 train_loss=0.68784 valid_u_score=1897.06989 valid_auc=0.55022 time: 177.96min\n",
      "FOLD7 EPOCH:  7 train_loss=0.68744 valid_u_score=2024.16050 valid_auc=0.55025 time: 178.87min\n",
      "FOLD7 EPOCH:  8 train_loss=0.68716 valid_u_score=1822.92792 valid_auc=0.55151 time: 179.79min\n",
      "FOLD7 EPOCH:  9 train_loss=0.68688 valid_u_score=2123.73790 valid_auc=0.55040 time: 180.71min\n",
      "FOLD7 EPOCH: 10 train_loss=0.68661 valid_u_score=1932.72537 valid_auc=0.55127 time: 181.62min\n",
      "FOLD7 EPOCH: 11 train_loss=0.68628 valid_u_score=1585.01894 valid_auc=0.55032 time: 182.53min\n",
      "FOLD7 EPOCH: 12 train_loss=0.68604 valid_u_score=1733.49782 valid_auc=0.55053 time: 183.45min\n",
      "FOLD7 EPOCH: 13 train_loss=0.68562 valid_u_score=1681.29314 valid_auc=0.54917 time: 184.35min\n",
      "FOLD7 EPOCH: 14 train_loss=0.68538 valid_u_score=1626.88500 valid_auc=0.55088 time: 185.26min\n",
      "FOLD7 EPOCH: 15 train_loss=0.68507 valid_u_score=1871.29719 valid_auc=0.55069 time: 186.17min\n",
      "FOLD7 EPOCH: 16 train_loss=0.68469 valid_u_score=2060.18303 valid_auc=0.55344 time: 187.08min\n",
      "FOLD7 EPOCH: 17 train_loss=0.68452 valid_u_score=1548.15936 valid_auc=0.54938 time: 187.98min\n",
      "FOLD7 EPOCH: 18 train_loss=0.68412 valid_u_score=1639.30726 valid_auc=0.54977 time: 188.90min\n",
      "FOLD7 EPOCH: 19 train_loss=0.68375 valid_u_score=1631.44962 valid_auc=0.54956 time: 189.79min\n",
      "FOLD7 EPOCH: 20 train_loss=0.68351 valid_u_score=1692.23587 valid_auc=0.55186 time: 190.71min\n",
      "FOLD7 EPOCH: 21 train_loss=0.68315 valid_u_score=1506.54062 valid_auc=0.54794 time: 191.63min\n",
      "FOLD7 EPOCH: 22 train_loss=0.68293 valid_u_score=1511.11081 valid_auc=0.55048 time: 192.52min\n",
      "FOLD7 EPOCH: 23 train_loss=0.68254 valid_u_score=1078.41638 valid_auc=0.54872 time: 193.44min\n",
      "FOLD7 EPOCH: 24 train_loss=0.68229 valid_u_score=1889.62272 valid_auc=0.55009 time: 194.35min\n",
      "FOLD7 EPOCH: 25 train_loss=0.68199 valid_u_score=1605.64649 valid_auc=0.54849 time: 195.26min\n",
      "FOLD7 EPOCH: 26 train_loss=0.68175 valid_u_score=1709.96671 valid_auc=0.55116 time: 196.16min\n",
      "FOLD7 EPOCH: 27 train_loss=0.68139 valid_u_score=1397.25452 valid_auc=0.54686 time: 197.06min\n",
      "FOLD7 EPOCH: 28 train_loss=0.68120 valid_u_score=1697.79304 valid_auc=0.54847 time: 197.98min\n",
      "FOLD7 EPOCH: 29 train_loss=0.68087 valid_u_score=1651.00944 valid_auc=0.54891 time: 198.90min\n",
      "FOLD7 EPOCH: 30 train_loss=0.68063 valid_u_score=1804.70111 valid_auc=0.54894 time: 199.80min\n",
      "FOLD7 EPOCH: 31 train_loss=0.68044 valid_u_score=1231.85315 valid_auc=0.54619 time: 200.71min\n",
      "FOLD7 EPOCH: 32 train_loss=0.68016 valid_u_score=1241.37568 valid_auc=0.54709 time: 201.62min\n",
      "FOLD7 EPOCH: 33 train_loss=0.67993 valid_u_score=1715.71056 valid_auc=0.54759 time: 202.52min\n",
      "FOLD7 EPOCH: 34 train_loss=0.67978 valid_u_score=1685.07332 valid_auc=0.54878 time: 203.44min\n",
      "FOLD7 EPOCH: 35 train_loss=0.67949 valid_u_score=1410.90532 valid_auc=0.54703 time: 204.35min\n",
      "FOLD7 EPOCH: 36 train_loss=0.67925 valid_u_score=1440.05500 valid_auc=0.54580 time: 205.26min\n",
      "Early stopping\n",
      "Fold8:\n",
      "FOLD8 EPOCH:  0 train_loss=0.69232 valid_u_score=2180.39844 valid_auc=0.54708 time: 206.17min\n",
      "FOLD8 EPOCH:  1 train_loss=0.68972 valid_u_score=1925.87171 valid_auc=0.54747 time: 207.08min\n",
      "FOLD8 EPOCH:  2 train_loss=0.68921 valid_u_score=2154.53911 valid_auc=0.55140 time: 207.98min\n",
      "FOLD8 EPOCH:  3 train_loss=0.68870 valid_u_score=1964.24827 valid_auc=0.54941 time: 208.88min\n",
      "FOLD8 EPOCH:  4 train_loss=0.68838 valid_u_score=1973.96076 valid_auc=0.55011 time: 209.79min\n",
      "FOLD8 EPOCH:  5 train_loss=0.68815 valid_u_score=1999.86275 valid_auc=0.55003 time: 210.69min\n",
      "FOLD8 EPOCH:  6 train_loss=0.68777 valid_u_score=1929.03197 valid_auc=0.55099 time: 211.60min\n",
      "FOLD8 EPOCH:  7 train_loss=0.68745 valid_u_score=1575.48638 valid_auc=0.54768 time: 212.50min\n",
      "FOLD8 EPOCH:  8 train_loss=0.68725 valid_u_score=1942.54102 valid_auc=0.55149 time: 213.41min\n",
      "FOLD8 EPOCH:  9 train_loss=0.68692 valid_u_score=1938.45040 valid_auc=0.55334 time: 214.32min\n",
      "FOLD8 EPOCH: 10 train_loss=0.68667 valid_u_score=1702.91944 valid_auc=0.55016 time: 215.21min\n",
      "FOLD8 EPOCH: 11 train_loss=0.68633 valid_u_score=1562.47339 valid_auc=0.54903 time: 216.13min\n",
      "FOLD8 EPOCH: 12 train_loss=0.68608 valid_u_score=1897.52090 valid_auc=0.54984 time: 217.05min\n",
      "FOLD8 EPOCH: 13 train_loss=0.68578 valid_u_score=1944.68092 valid_auc=0.55103 time: 217.95min\n",
      "FOLD8 EPOCH: 14 train_loss=0.68547 valid_u_score=1728.46990 valid_auc=0.54965 time: 218.86min\n",
      "FOLD8 EPOCH: 15 train_loss=0.68523 valid_u_score=1888.51502 valid_auc=0.55061 time: 219.78min\n",
      "FOLD8 EPOCH: 16 train_loss=0.68492 valid_u_score=1525.19044 valid_auc=0.54965 time: 220.70min\n",
      "FOLD8 EPOCH: 17 train_loss=0.68453 valid_u_score=1397.18640 valid_auc=0.54952 time: 221.60min\n",
      "FOLD8 EPOCH: 18 train_loss=0.68420 valid_u_score=1703.46396 valid_auc=0.55046 time: 222.52min\n",
      "FOLD8 EPOCH: 19 train_loss=0.68389 valid_u_score=1790.55421 valid_auc=0.55019 time: 223.43min\n",
      "FOLD8 EPOCH: 20 train_loss=0.68358 valid_u_score=1625.05577 valid_auc=0.54878 time: 224.34min\n",
      "FOLD8 EPOCH: 21 train_loss=0.68326 valid_u_score=1579.09921 valid_auc=0.54829 time: 225.25min\n",
      "FOLD8 EPOCH: 22 train_loss=0.68300 valid_u_score=1715.70884 valid_auc=0.55018 time: 226.17min\n",
      "FOLD8 EPOCH: 23 train_loss=0.68263 valid_u_score=1600.93928 valid_auc=0.54819 time: 227.08min\n",
      "FOLD8 EPOCH: 24 train_loss=0.68232 valid_u_score=1586.90194 valid_auc=0.54787 time: 228.00min\n",
      "FOLD8 EPOCH: 25 train_loss=0.68214 valid_u_score=1735.69625 valid_auc=0.54981 time: 228.91min\n",
      "FOLD8 EPOCH: 26 train_loss=0.68179 valid_u_score=1618.41363 valid_auc=0.54774 time: 229.82min\n",
      "FOLD8 EPOCH: 27 train_loss=0.68162 valid_u_score=1399.97834 valid_auc=0.54737 time: 230.73min\n",
      "FOLD8 EPOCH: 28 train_loss=0.68123 valid_u_score=1685.56935 valid_auc=0.54898 time: 231.66min\n",
      "FOLD8 EPOCH: 29 train_loss=0.68103 valid_u_score=1768.75617 valid_auc=0.54781 time: 232.57min\n",
      "Early stopping\n",
      "Fold9:\n",
      "FOLD9 EPOCH:  0 train_loss=0.69240 valid_u_score=1877.61997 valid_auc=0.54686 time: 233.47min\n",
      "FOLD9 EPOCH:  1 train_loss=0.68973 valid_u_score=2134.57325 valid_auc=0.54807 time: 234.38min\n",
      "FOLD9 EPOCH:  2 train_loss=0.68909 valid_u_score=2013.76369 valid_auc=0.54848 time: 235.29min\n",
      "FOLD9 EPOCH:  3 train_loss=0.68869 valid_u_score=1892.99125 valid_auc=0.54954 time: 236.19min\n",
      "FOLD9 EPOCH:  4 train_loss=0.68834 valid_u_score=2077.86314 valid_auc=0.55069 time: 237.10min\n",
      "FOLD9 EPOCH:  5 train_loss=0.68805 valid_u_score=2191.88549 valid_auc=0.55134 time: 238.00min\n",
      "FOLD9 EPOCH:  6 train_loss=0.68777 valid_u_score=2091.55104 valid_auc=0.55141 time: 238.89min\n",
      "FOLD9 EPOCH:  7 train_loss=0.68747 valid_u_score=1935.32774 valid_auc=0.54969 time: 239.80min\n",
      "FOLD9 EPOCH:  8 train_loss=0.68724 valid_u_score=1928.57190 valid_auc=0.55002 time: 240.71min\n",
      "FOLD9 EPOCH:  9 train_loss=0.68688 valid_u_score=1809.40178 valid_auc=0.54983 time: 241.62min\n",
      "FOLD9 EPOCH: 10 train_loss=0.68664 valid_u_score=1707.24812 valid_auc=0.54849 time: 242.54min\n",
      "FOLD9 EPOCH: 11 train_loss=0.68638 valid_u_score=2021.00347 valid_auc=0.55115 time: 243.45min\n",
      "FOLD9 EPOCH: 12 train_loss=0.68609 valid_u_score=1907.10996 valid_auc=0.55122 time: 244.35min\n",
      "FOLD9 EPOCH: 13 train_loss=0.68573 valid_u_score=2117.29941 valid_auc=0.55051 time: 245.26min\n",
      "FOLD9 EPOCH: 14 train_loss=0.68544 valid_u_score=1037.36640 valid_auc=0.54853 time: 246.17min\n",
      "FOLD9 EPOCH: 15 train_loss=0.68515 valid_u_score=1601.76516 valid_auc=0.54980 time: 247.06min\n",
      "FOLD9 EPOCH: 16 train_loss=0.68471 valid_u_score=1529.26039 valid_auc=0.54885 time: 247.96min\n",
      "FOLD9 EPOCH: 17 train_loss=0.68443 valid_u_score=1421.80449 valid_auc=0.55075 time: 248.86min\n",
      "FOLD9 EPOCH: 18 train_loss=0.68416 valid_u_score=1379.47570 valid_auc=0.54691 time: 249.75min\n",
      "FOLD9 EPOCH: 19 train_loss=0.68371 valid_u_score=1577.93359 valid_auc=0.54743 time: 250.65min\n",
      "FOLD9 EPOCH: 20 train_loss=0.68359 valid_u_score=1828.66990 valid_auc=0.54912 time: 251.54min\n",
      "FOLD9 EPOCH: 21 train_loss=0.68307 valid_u_score=1484.05896 valid_auc=0.54948 time: 252.44min\n",
      "FOLD9 EPOCH: 22 train_loss=0.68284 valid_u_score=1664.72161 valid_auc=0.55043 time: 253.33min\n",
      "FOLD9 EPOCH: 23 train_loss=0.68247 valid_u_score=1327.65174 valid_auc=0.54757 time: 254.24min\n",
      "FOLD9 EPOCH: 24 train_loss=0.68227 valid_u_score=1636.33844 valid_auc=0.54778 time: 255.15min\n",
      "FOLD9 EPOCH: 25 train_loss=0.68190 valid_u_score=1784.36835 valid_auc=0.54893 time: 256.06min\n",
      "FOLD9 EPOCH: 26 train_loss=0.68170 valid_u_score=1387.17180 valid_auc=0.54791 time: 256.95min\n",
      "Early stopping\n",
      "10 models valid score: 2268.706921713726\tauc_score: 0.5557\tlogloss_score:4.0699\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "DATA_PATH = '../input/jane-street-market-prediction/'\n",
    "\n",
    "# GPU_NUM = 8\n",
    "BATCH_SIZE = 8192# * GPU_NUM\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EARLYSTOP_NUM = 20\n",
    "NFOLDS = 10\n",
    "\n",
    "TRAIN = True\n",
    "CACHE_PATH = './'\n",
    "\n",
    "train = pd.read_csv(f'{DATA_PATH}/train.csv')\n",
    "\n",
    "def save_pickle(dic, save_path):\n",
    "    with open(save_path, 'wb') as f:\n",
    "    # with gzip.open(save_path, 'wb') as f:\n",
    "        pickle.dump(dic, f)\n",
    "\n",
    "def load_pickle(load_path):\n",
    "    with open(load_path, 'rb') as f:\n",
    "    # with gzip.open(load_path, 'rb') as f:\n",
    "        message_dict = pickle.load(f)\n",
    "    return message_dict\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model, model_path):\n",
    "\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "        else:\n",
    "            score = np.copy(epoch_score)\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "        elif score < self.best_score: #  + self.delta\n",
    "            self.counter += 1\n",
    "            # print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            # ema.apply_shadow()\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "            # ema.restore()\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model, model_path):\n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            # print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))\n",
    "            # if not DEBUG:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        self.val_score = epoch_score\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=42)\n",
    "\n",
    "feat_cols = [f'feature_{i}' for i in range(130)]\n",
    "\n",
    "if TRAIN:\n",
    "    train = train.loc[train.date > 85].reset_index(drop=True)\n",
    "\n",
    "    train['action'] = (train['resp'] > 0).astype('int')\n",
    "    train['action_1'] = (train['resp_1'] > 0).astype('int')\n",
    "    train['action_2'] = (train['resp_2'] > 0).astype('int')\n",
    "    train['action_3'] = (train['resp_3'] > 0).astype('int')\n",
    "    train['action_4'] = (train['resp_4'] > 0).astype('int')\n",
    "    valid = train.loc[(train.date >= 450) & (train.date < 500)].reset_index(drop=True)\n",
    "    train = train.loc[train.date < 450].reset_index(drop=True)\n",
    "target_cols = ['action', 'action_1', 'action_2', 'action_3', 'action_4']\n",
    "\n",
    "if TRAIN:\n",
    "    df = pd.concat([train[feat_cols], valid[feat_cols]]).reset_index(drop=True)\n",
    "    f_mean = df.mean()\n",
    "    f_mean = f_mean.values\n",
    "    np.save(f'{CACHE_PATH}/f_mean_great85_online.npy', f_mean)\n",
    "\n",
    "    train.fillna(df.mean(), inplace=True)\n",
    "    valid.fillna(df.mean(), inplace=True)\n",
    "else:\n",
    "    f_mean = np.load(f'{CACHE_PATH}/f_mean_great85_online.npy')\n",
    "\n",
    "##### Making features\n",
    "# https://www.kaggle.com/lucasmorin/running-algos-fe-for-fast-inference/data\n",
    "# eda:https://www.kaggle.com/carlmcbrideellis/jane-street-eda-of-day-0-and-feature-importance\n",
    "# his example:https://www.kaggle.com/gracewan/plot-model\n",
    "def fillna_npwhere_njit(array, values):\n",
    "    if np.isnan(array.sum()):\n",
    "        array = np.where(np.isnan(array), values, array)\n",
    "    return array\n",
    "\n",
    "class RunningEWMean:\n",
    "    def __init__(self, WIN_SIZE=20, n_size=1, lt_mean=None):\n",
    "        if lt_mean is not None:\n",
    "            self.s = lt_mean\n",
    "        else:\n",
    "            self.s = np.zeros(n_size)\n",
    "        self.past_value = np.zeros(n_size)\n",
    "        self.alpha = 2 / (WIN_SIZE + 1)\n",
    "\n",
    "    def clear(self):\n",
    "        self.s = 0\n",
    "\n",
    "    def push(self, x):\n",
    "\n",
    "        x = fillna_npwhere_njit(x, self.past_value)\n",
    "        self.past_value = x\n",
    "        self.s = self.alpha * x + (1 - self.alpha) * self.s\n",
    "\n",
    "    def get_mean(self):\n",
    "        return self.s\n",
    "\n",
    "if TRAIN:\n",
    "    all_feat_cols = [col for col in feat_cols]\n",
    "\n",
    "    train['cross_41_42_43'] = train['feature_41'] + train['feature_42'] + train['feature_43']\n",
    "    train['cross_1_2'] = train['feature_1'] / (train['feature_2'] + 1e-5)\n",
    "    valid['cross_41_42_43'] = valid['feature_41'] + valid['feature_42'] + valid['feature_43']\n",
    "    valid['cross_1_2'] = valid['feature_1'] / (valid['feature_2'] + 1e-5)\n",
    "\n",
    "    all_feat_cols.extend(['cross_41_42_43', 'cross_1_2'])\n",
    "\n",
    "##### Model&Data fnc\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class MarketDataset:\n",
    "    def __init__(self, df):\n",
    "        self.features = df[all_feat_cols].values\n",
    "\n",
    "        self.label = df[target_cols].values.reshape(-1, len(target_cols))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.features[idx], dtype=torch.float),\n",
    "            'label': torch.tensor(self.label[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm0 = nn.BatchNorm1d(len(all_feat_cols))\n",
    "        self.dropout0 = nn.Dropout(0.2)\n",
    "\n",
    "        dropout_rate = 0.2\n",
    "        hidden_size = 256\n",
    "        self.dense1 = nn.Linear(len(all_feat_cols), hidden_size)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense2 = nn.Linear(hidden_size+len(all_feat_cols), hidden_size)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense5 = nn.Linear(hidden_size+hidden_size, len(target_cols))\n",
    "\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "        self.PReLU = nn.PReLU()\n",
    "        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        # self.GeLU = nn.GELU()\n",
    "        self.RReLU = nn.RReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm0(x)\n",
    "        x = self.dropout0(x)\n",
    "\n",
    "        x1 = self.dense1(x)\n",
    "        x1 = self.batch_norm1(x1)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x1 = self.LeakyReLU(x1)\n",
    "        x1 = self.dropout1(x1)\n",
    "\n",
    "        x = torch.cat([x, x1], 1)\n",
    "\n",
    "        x2 = self.dense2(x)\n",
    "        x2 = self.batch_norm2(x2)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x2 = self.LeakyReLU(x2)\n",
    "        x2 = self.dropout2(x2)\n",
    "\n",
    "        x = torch.cat([x1, x2], 1)\n",
    "\n",
    "        x3 = self.dense3(x)\n",
    "        x3 = self.batch_norm3(x3)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x3 = self.LeakyReLU(x3)\n",
    "        x3 = self.dropout3(x3)\n",
    "\n",
    "        x = torch.cat([x2, x3], 1)\n",
    "\n",
    "        x4 = self.dense4(x)\n",
    "        x4 = self.batch_norm4(x4)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x4 = self.LeakyReLU(x4)\n",
    "        x4 = self.dropout4(x4)\n",
    "\n",
    "        x = torch.cat([x3, x4], 1)\n",
    "\n",
    "        x = self.dense5(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        features = data['features'].to(device)\n",
    "        label = data['label'].to(device)\n",
    "        outputs = model(features)\n",
    "        loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        final_loss += loss.item()\n",
    "\n",
    "    final_loss /= len(dataloader)\n",
    "\n",
    "    return final_loss\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        features = data['features'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(features)\n",
    "\n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds).reshape(-1, len(target_cols))\n",
    "\n",
    "    return preds\n",
    "\n",
    "def utility_score_bincount(date, weight, resp, action):\n",
    "    count_i = len(np.unique(date))\n",
    "    # print('weight: ', weight)\n",
    "    # print('resp: ', resp)\n",
    "    # print('action: ', action)\n",
    "    # print('weight * resp * action: ', weight * resp * action)\n",
    "    Pi = np.bincount(date, weight * resp * action)\n",
    "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n",
    "    u = np.clip(t, 0, 6) * np.sum(Pi)\n",
    "    return u\n",
    "\n",
    "if TRAIN:\n",
    "    train_set = MarketDataset(train)\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    valid_set = MarketDataset(valid)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _fold in range(NFOLDS):\n",
    "        print(f'Fold{_fold}:')\n",
    "        seed_everything(seed=42+_fold)\n",
    "        torch.cuda.empty_cache()\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        model = Model()\n",
    "        model.to(device)\n",
    "        # model = nn.DataParallel(model)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "        # optimizer = Nadam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "        # optimizer = Lookahead(optimizer=optimizer, k=10, alpha=0.5)\n",
    "        scheduler = None\n",
    "        # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3,\n",
    "        #                                                 max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(train_loader))\n",
    "        # loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss_fn = SmoothBCEwLogits(smoothing=0.005)\n",
    "\n",
    "        model_weights = f\"{CACHE_PATH}/online_great85_model{_fold}.pth\"\n",
    "        es = EarlyStopping(patience=EARLYSTOP_NUM, mode=\"max\")\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss = train_fn(model, optimizer, scheduler, loss_fn, train_loader, device)\n",
    "\n",
    "            valid_pred = inference_fn(model, valid_loader, device)\n",
    "            valid_auc = roc_auc_score(valid[target_cols].values, valid_pred)\n",
    "            valid_logloss = log_loss(valid[target_cols].values, valid_pred)\n",
    "            valid_pred = np.median(valid_pred, axis=1)\n",
    "            valid_pred = np.where(valid_pred >= 0.5, 1, 0).astype(int)\n",
    "            valid_u_score = utility_score_bincount(date=valid.date.values, weight=valid.weight.values,\n",
    "                                                   resp=valid.resp.values, action=valid_pred)\n",
    "            print(f\"FOLD{_fold} EPOCH:{epoch:3} train_loss={train_loss:.5f} \"\n",
    "                      f\"valid_u_score={valid_u_score:.5f} valid_auc={valid_auc:.5f} \"\n",
    "                      f\"time: {(time.time() - start_time) / 60:.2f}min\")\n",
    "            es(valid_auc, model, model_path=model_weights)\n",
    "            if es.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        # torch.save(model.state_dict(), model_weights)\n",
    "    if True:\n",
    "        valid_pred = np.zeros((len(valid), len(target_cols)))\n",
    "        for _fold in range(NFOLDS):\n",
    "            torch.cuda.empty_cache()\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            model = Model()\n",
    "            model.to(device)\n",
    "            model_weights = f\"{CACHE_PATH}/online_great85_model{_fold}.pth\"\n",
    "            model.load_state_dict(torch.load(model_weights))\n",
    "\n",
    "            valid_pred += inference_fn(model, valid_loader, device) / NFOLDS\n",
    "        auc_score = roc_auc_score(valid[target_cols].values, valid_pred)\n",
    "        logloss_score = log_loss(valid[target_cols].values, valid_pred)\n",
    "\n",
    "        valid_pred = np.median(valid_pred, axis=1)\n",
    "        valid_pred = np.where(valid_pred >= 0.5, 1, 0).astype(int)\n",
    "        valid_score = utility_score_bincount(date=valid.date.values, weight=valid.weight.values, resp=valid.resp.values,\n",
    "                                             action=valid_pred)\n",
    "        print(f'{NFOLDS} models valid score: {valid_score}\\tauc_score: {auc_score:.4f}\\tlogloss_score:{logloss_score:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15693.113914,
   "end_time": "2021-02-10T16:27:56.145672",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-10T12:06:23.031758",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
